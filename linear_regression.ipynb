{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcf165a-ab67-4a34-865b-b4e533cf93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython.display import display, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ee234-45d7-46b8-9925-7d78d8e0e537",
   "metadata": {},
   "source": [
    "# [Linear Regression](https://en.wikipedia.org/wiki/Linear_regression)\n",
    "\n",
    "> [Interpreting computer output for regression](https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/assessing-the-fit-in-least-squares-regression/a/interpreting-computer-output-regression): Association does not necessarily imply causation.\n",
    "\n",
    "\n",
    "In [statistics](https://en.wikipedia.org/wiki/Statistics \"Statistics\"), **linear regression** is a [linear](https://en.wikipedia.org/wiki/Linearity \"Linearity\") approach for modelling the relationship between a [scalar](https://en.wikipedia.org/wiki/Scalar_(mathematics) \"Scalar (mathematics)\") response and one or more explanatory variables (also known as [dependent and independent variables](https://en.wikipedia.org/wiki/Dependent_and_independent_variables \"Dependent and independent variables\")). The case of one explanatory variable is called _[simple linear regression](https://en.wikipedia.org/wiki/Simple_linear_regression \"Simple linear regression\")_; for more than one, the process is called **multiple linear regression**.[[1]](https://en.wikipedia.org/wiki/Linear_regression#cite_note-Freedman09-1) This term is distinct from [multivariate linear regression](https://en.wikipedia.org/wiki/Multivariate_linear_regression \"Multivariate linear regression\"), where multiple [correlated](https://en.wikipedia.org/wiki/Correlation_and_dependence \"Correlation and dependence\") dependent variables are predicted, rather than a single scalar variable.\n",
    "\n",
    "- $\\displaystyle \\hat y = a + bx$\n",
    "- $\\displaystyle b = r\\frac{s_y}{s_x}$\n",
    "- $\\displaystyle a = \\bar y - b \\bar x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e15796-1f48-4abd-b732-879bfd581b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_reg(mu_x, mu_y, sd_x, sd_y, r):\n",
    "    b = r * (sd_y / sd_x)\n",
    "    a = mu_y - b * mu_x\n",
    "    display(Latex(f\"$\\hat y = {round(a, 3)} + {round(b, 3)}x$\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22b1abb-e1d3-4889-873f-a1043579f948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\hat y = 86.048 + -1.32x$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu_x, mu_y, sd_x, sd_y, r = 8.9, 74.3, 4.8, 7.2, -0.88\n",
    "linear_reg(mu_x, mu_y, sd_x, sd_y, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db31a937-04a7-4835-9089-62aca898a43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\hat y = -0.238 + 0.976x$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$R^2 = 0.88$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([[-2], [-1], [1], [4]])\n",
    "y = np.array([-3, -1, 2, 3])\n",
    "reg = LinearRegression().fit(X, y)\n",
    "a = reg.intercept_\n",
    "b = reg.coef_[0]\n",
    "r_squared = reg.score(X, y)\n",
    "precision = 3\n",
    "\n",
    "display(Latex(f\"$\\hat y = {round(a, precision)} + {round(b, precision)}x$\"))\n",
    "display(Latex(f\"$R^2 = {round(r_squared, precision)}$\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c73fce0-d606-460c-83db-e88f10356204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=0.9761904761904762, intercept=-0.23809523809523808, rvalue=0.9378934722869389, pvalue=0.062106527713061126, stderr=0.25532869749437176, intercept_stderr=0.5987988733313951)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(len(X)) # reshape X\n",
    "linregress(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90375ac-8666-448d-b518-22dd4d1c5c24",
   "metadata": {},
   "source": [
    "## [Errors and residuals](https://en.wikipedia.org/wiki/Errors_and_residuals)\n",
    "\n",
    "In [statistics](https://en.wikipedia.org/wiki/Statistics \"Statistics\") and [optimization](https://en.wikipedia.org/wiki/Mathematical_optimization \"Mathematical optimization\"), **errors** and **residuals** are two closely related and easily confused measures of the [deviation](https://en.wikipedia.org/wiki/Deviation_(statistics) \"Deviation (statistics)\") of an [observed value](https://en.wikipedia.org/wiki/Observed_value \"Observed value\") of an [element](https://en.wikipedia.org/wiki/Elementary_event \"Elementary event\") of a [statistical sample](https://en.wikipedia.org/wiki/Sample_(statistics) \"Sample (statistics)\") from its \"[true value](https://en.wikipedia.org/wiki/True_value \"True value\")\" (not necessarily observable). \n",
    "\n",
    "- The **error** (or **disturbance**) of an [observation](https://en.wikipedia.org/wiki/Observation \"Observation\") is the deviation of the observed value from the true value of a quantity of interest (for example, a [population mean](https://en.wikipedia.org/wiki/Population_mean \"Population mean\")). \n",
    "- The **residual** is the difference between the observed value and the _[estimated](https://en.wikipedia.org/wiki/Estimation \"Estimation\")_ value of the quantity of interest (for example, a [sample mean](https://en.wikipedia.org/wiki/Sample_mean \"Sample mean\")). \n",
    "\n",
    "The distinction is most important in [regression analysis](https://en.wikipedia.org/wiki/Regression_analysis \"Regression analysis\"), where the concepts are sometimes called the **regression errors** and **regression residuals** and where they lead to the concept of [studentized residuals](https://en.wikipedia.org/wiki/Studentized_residual \"Studentized residual\").\n",
    "\n",
    "- $\\displaystyle e_i = X_i - \\mu$\n",
    "- $\\displaystyle r_i = X_i - \\bar X$\n",
    "\n",
    "The standard deviation of the residuals, or $S$, measures the size of a typical prediction error in the $y$ variable. So the units of $S$ match the units on the $y$-variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c81845-1001-4340-af00-874ee2c7f75c",
   "metadata": {},
   "source": [
    "## [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
    "\n",
    "In [statistics](https://en.wikipedia.org/wiki/Statistics \"Statistics\"), the **Pearson correlation coefficient** (**PCC**) ― also known as **Pearson's _r_**, the **Pearson product-moment correlation coefficient** (**PPMCC**), the **bivariate correlation**,[[1]](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#cite_note-1) or colloquially simply as **the correlation coefficient**[[2]](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#cite_note-2) ― is a measure of [linear](https://en.wikipedia.org/wiki/Linear \"Linear\") [correlation](https://en.wikipedia.org/wiki/Correlation_and_dependence \"Correlation and dependence\") between two sets of data. It is the ratio between the [covariance](https://en.wikipedia.org/wiki/Covariance \"Covariance\") of two variables and the product of their [standard deviations](https://en.wikipedia.org/wiki/Standard_deviation \"Standard deviation\"); thus it is essentially a normalized measurement of the covariance, such that the result always has a value between −1 and 1. As with covariance itself, the measure can only reflect a linear correlation of variables, and ignores many other types of relationship or correlation. As a simple example, one would expect the age and height of a sample of teenagers from a high school to have a Pearson correlation coefficient significantly greater than 0, but less than 1 (as 1 would represent an unrealistically perfect correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a227c63d-5c97-42a0-a758-36c65784bb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=-0.1518881489028096, intercept=0.5148172723635894, rvalue=-0.20274585383366478, pvalue=0.5742789390728125, stderr=0.25936552064492635, intercept_stderr=0.12344737360893261)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.random(10)\n",
    "y = np.random.random(10)\n",
    "slope, intercept, r_value, p_value, std_err = linregress(X, y)\n",
    "linregress(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a19fbfa9-7b63-499a-b6b8-ff322a92b927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\hat y = 0.515 + -0.152x$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$R^2 = 0.041$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = X.reshape(len(X), 1) # reshape X\n",
    "reg = LinearRegression().fit(X, y)\n",
    "a = reg.intercept_\n",
    "b = reg.coef_[0]\n",
    "r_squared = reg.score(X, y)\n",
    "precision = 3\n",
    "\n",
    "display(Latex(f\"$\\hat y = {round(a, precision)} + {round(b, precision)}x$\"))\n",
    "display(Latex(f\"$R^2 = {round(r_squared, precision)}$\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06812553-0b6e-4938-9738-464b3b294707",
   "metadata": {},
   "source": [
    "## [R-squared](https://en.wikipedia.org/wiki/Coefficient_of_determination) (coefficient of determination)\n",
    "\n",
    "> [R-squared intuition](https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/assessing-the-fit-in-least-squares-regression/a/r-squared-intuition)\n",
    "\n",
    "R-squared tells us what percent of the prediction error in the $y$ variable is eliminated when we use least-squares regression on the $x$ variable.\n",
    "\n",
    "As a result, $r^2$ is also called the **coefficient of determination**.\n",
    "\n",
    "Many formal definitions say that $r^2$ tells us what percent of the variability in the $y$ variable is accounted for by the regression on the $x$ variable.\n",
    "\n",
    "It seems pretty remarkable that simply squaring $r$ gives us this measurement. Proving this relationship between $r$ and $r^2$ is pretty complex, and is beyond the scope of an introductory statistics course.\n",
    "\n",
    "- $\\displaystyle \\bar y = \\frac{1}{n} \\sum^n_{i=1}{y_i}$\n",
    "- $\\displaystyle SS_{res} = \\sum_{i}(y_i - f_i)^2 = \\sum_{i}e^2_i$\n",
    "- $\\displaystyle SS_{tot} = \\sum_{i}(y_i - \\bar y)^2$\n",
    "- $\\displaystyle R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ee060-85df-4b6e-8b8c-302e0a4e6b57",
   "metadata": {},
   "source": [
    "## [Root-mean-squre deviation](https://en.wikipedia.org/wiki/Root-mean-square_deviation)\n",
    "\n",
    "- $\\displaystyle RMSE = RMSD = \\sqrt{\\frac{\\sum^N_{i=1}(x_i - \\hat x_i)^2}{N}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addfd883-4569-41c8-894b-4a981c9c2cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statistics-and-probability",
   "language": "python",
   "name": "statistics-and-probability"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
